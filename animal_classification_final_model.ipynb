{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8sQB71RNVyf",
        "colab_type": "text"
      },
      "source": [
        "# **Animal Classification**\n",
        "这是动物分类器的Notebook，包括训练、测试、保存模型过程。\n",
        "\n",
        "本项目用到的技术包括神经网络，随机森林，朴素贝叶斯，支持向量机，K最近邻等。\n",
        "\n",
        "Notebook运行于Google Colab free云训练平台。\n",
        "\n",
        "环境详情：\n",
        "\n",
        "CPU 2*2.30GHz，GPU TeslaH T4，Memory 12.72GB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfxhCCCQRCXG",
        "colab_type": "text"
      },
      "source": [
        "# **数据解压**\n",
        "\n",
        "由于数据集保存在Google云硬盘中，直接读取速度非常缓慢。\n",
        "\n",
        "为了实现快速读取，增加解压步骤如下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HHvvg8gMTZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "file_dir = 'drive/My Drive/dataset.zip'  # 你的压缩包路径\n",
        "zipFile = zipfile.ZipFile(file_dir)\n",
        "for file in zipFile.namelist():\n",
        "    zipFile.extract(file, '/content')  # 解压路径\n",
        "zipFile.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0-KR_RjRBzh",
        "colab_type": "text"
      },
      "source": [
        "# **环境加载**\n",
        "\n",
        "本项目主要使用Numpy，Scikit-Learn，Tensorflow，Keras，Time，Os，OpenCV等第三方库实现项目。\n",
        "\n",
        "该步骤用于加载本项目中用到的所有库和库函数。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MH-aFHTbFko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "import tensorflow as tf\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGkymnthU0d5",
        "colab_type": "text"
      },
      "source": [
        "# **数据加载**\n",
        "\n",
        "加载训练、测试数据。\n",
        "\n",
        "读入图片的同时给数据加上标签，方便训练。\n",
        "\n",
        "经过多次尝试，平衡训练时间和模型性能的结果，训练集包括每类601张图片，共3606张，其余图片作为测试数据，共554张。\n",
        "\n",
        "图片读入时利用OpenCV，同时进行裁剪，使数据形状为(224,224,3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zjTCFNgIFrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#categories = {'cane': 'dog', 'gatto': 'cat'，\"cavallo\": \"horse\",\"mucca\": \"cow\", \"pecora\": \"sheep\"，\"chicken\": \"gallina\"}\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "animals = ['dog', 'cat', 'chicken', 'cow', 'horse', 'sheep']\n",
        "path=\"dataset/\"\n",
        "i = 0;\n",
        "for files in animals:\n",
        "    j = 0;\n",
        "    for img in os.listdir(path+files):\n",
        "        try:\n",
        "            img_array = cv2.imread(path+files+'/'+img)\n",
        "            new_img = cv2.resize(img_array, (224,224))\n",
        "            #if j == 240: break\n",
        "            if j <= 600:\n",
        "                x_train.append([new_img])\n",
        "                y_train.append(i)\n",
        "            else:\n",
        "                x_test.append([new_img])\n",
        "                y_test.append(i)\n",
        "            j = j + 1\n",
        "        except: pass\n",
        "    i = i + 1\n",
        "    print(\"Load \",files,\"...\") \n",
        "x_train = np.array(x_train)\n",
        "x_train = np.squeeze(x_train)\n",
        "x_test = np.array(x_test)\n",
        "x_test = np.squeeze(x_test)\n",
        "print(\"x_train shape\", np.array(x_train).shape)\n",
        "print(\"x_test shape\", np.array(x_test).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtI0T4JnWEHZ",
        "colab_type": "text"
      },
      "source": [
        "# **数据预处理**\n",
        "\n",
        "包括数据的形状调整和特征抽取。\n",
        "\n",
        "该部分利用了卷积神经网络模型VGG16除去全连接层的部分进行特征抽取，参数使用预训练模型imagenet，该模型可以对1000种物体进行效果良好的分类，可以用于本项目的使用，进行迁移学习。\n",
        "\n",
        "利用VGG16的特征抽取，可以获得有效特征，提高分类准确度。同时也可以数据降维，把(224,224,3)共150,528‬维降维至(7,7,512)共25088维。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5L1Jx9CthFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vgg16 = VGG16(weights='imagenet', include_top=False)\n",
        "print(\"Feature Extractor information:\")\n",
        "model_vgg16.summary()\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "x_train = preprocess_input(x_train)\n",
        "\n",
        "\n",
        "x_train = model_vgg16.predict(x_train)\n",
        "\n",
        "\n",
        "x_test = preprocess_input(x_test)\n",
        "x_test = model_vgg16.predict(x_test)\n",
        "print(\"x_train.shape\",x_train.shape)\n",
        "print(\"x_test.shape\",x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKXb9HviYD1I",
        "colab_type": "text"
      },
      "source": [
        "# **神经网络**\n",
        "实现了神经网络分类器的设计和训练。\n",
        "\n",
        "共4层，第一层全连接层flatten；第二层隐藏层4096个神经元，relu激活；第三层512个神经元，relu激活；第四层输出6个神经元，softmax激活。\n",
        "\n",
        "输入形状为(7,7,512)，15个epochs，使用adam优化。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2B4Ay5MafyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_to_category(a):\n",
        "    max2 = []\n",
        "    for item in a:\n",
        "        i=np.argmax(item)\n",
        "        max2.append(i)\n",
        "    return max2\n",
        "\n",
        "net = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax'),\n",
        "])\n",
        "net.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "startt = time.time()\n",
        "net.fit(x_train, y_train, epochs=15)\n",
        "net_traintime = time.time() - startt\n",
        "print(net.evaluate(x_test, y_test))\n",
        "net_pred = softmax_to_category(net.predict(x_test))\n",
        "print(\"Nerual Network Summary:\")\n",
        "net.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNXu4pWBYfZH",
        "colab_type": "text"
      },
      "source": [
        "# **数据二次处理**\n",
        "\n",
        "使用其他分类器，将数据进行flatten操作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmx-qMdo78nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"flatten the data:\")\n",
        "x1_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x1_test = x_test.reshape(x_test.shape[0], -1)\n",
        "print(\"x1_train.shape\",x1_train.shape)\n",
        "print(\"x1_test.shape\",x1_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjaH8C5NY1fQ",
        "colab_type": "text"
      },
      "source": [
        "# **朴素贝叶斯分类器**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4fODFkp0phv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gnb = GaussianNB()\n",
        "startt = time.time()\n",
        "gnb.fit(x1_train, y_train)\n",
        "bayes_traintime = time.time() - startt\n",
        "bayes_pred = gnb.predict(x1_test)\n",
        "print(\"Finish the naive_bayes classification.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h11eiVpzZAqp",
        "colab_type": "text"
      },
      "source": [
        "# **随机森林分类器**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vASo6lJ81MMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf0 = RandomForestClassifier(oob_score=True, random_state=10)\n",
        "startt = time.time()\n",
        "rf0.fit(x1_train, y_train)\n",
        "rf_traintime = time.time() - startt\n",
        "rf_pred = rf0.predict(x1_test)\n",
        "print(\"Finish the random forest classification.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seHU8ljUZDW4",
        "colab_type": "text"
      },
      "source": [
        "# **K最近邻分类器**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_0Q4Hx_1Sjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier() \n",
        "startt = time.time()\n",
        "knn.fit(x1_train, y_train)\n",
        "knn_traintime = time.time() - startt\n",
        "knn_pred = knn.predict(x1_test)\n",
        "print(\"Finish the knn classification.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VTIMqw0ZG0P",
        "colab_type": "text"
      },
      "source": [
        "# **支持向量机分类器**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxmM9cjkhaGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm = SVC(kernel='rbf')\n",
        "startt = time.time()\n",
        "svm.fit(x1_train, y_train)\n",
        "svm_traintime = time.time() - startt\n",
        "svm_pred = svm.predict(x1_test)\n",
        "print(\"Finish the svm classification.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9EVckqYZKzX",
        "colab_type": "text"
      },
      "source": [
        "# **分类器性能分析报表**\n",
        "\n",
        "包括每种分类器在每一类上和总体平均的Precision，Recall，F1和训练耗费时间。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ4dlWckhfrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Evaluation Reports\")\n",
        "print(\"Naive Bayes:\")\n",
        "print(classification_report(y_test, bayes_pred, target_names=animals))\n",
        "print(\"Naive Bayes Train Time: \", bayes_traintime, 's')\n",
        "print(\"Random Forest:\")\n",
        "print(classification_report(y_test, rf_pred, target_names=animals))\n",
        "print(\"Random Forest Train Time: \", rf_traintime, 's')\n",
        "print(\"KNN:\")\n",
        "print(classification_report(y_test, knn_pred, target_names=animals))\n",
        "print(\"KNN Train Time: \", knn_traintime, 's')\n",
        "print(\"SVM:\")\n",
        "print(classification_report(y_test, svm_pred, target_names=animals))\n",
        "print(\"SVM Train Time: \", svm_traintime, 's')\n",
        "print(\"Neural Network:\")\n",
        "print(classification_report(y_test, net_pred, target_names=animals))\n",
        "print(\"Neural Network Train Time: \", net_traintime, 's')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhhYJMf_Zc1g",
        "colab_type": "text"
      },
      "source": [
        "# **保存模型**\n",
        "\n",
        "保存模型，方便其他用途不必再次训练。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqZ6oNNHBsfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Save the classification model...\")\n",
        "print(\"save the net...\")\n",
        "net.save(\"net_model.h5\")\n",
        "print(\"save the bayes...\")\n",
        "joblib.dump(gnb,\"bayes_model.m\")\n",
        "print(\"save the knn...\")\n",
        "joblib.dump(knn,\"knn_model.m\")\n",
        "print(\"save the rf...\")\n",
        "joblib.dump(rf0,\"rf_model.m\")\n",
        "print(\"save the svm...\")\n",
        "joblib.dump(svm,\"svm_model.m\")\n",
        "print(\"finish!\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}